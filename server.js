const express = require('express');
const cors = require('cors');
const http = require('http');
const socketIo = require('socket.io');

const app = express();
const server = http.createServer(app);
const io = socketIo(server, {
  cors: {
    origin: ["http://localhost:3000", "http://localhost:5173", "https://ungenerous-ropy-yuk.ngrok-free.dev"],
    methods: ["GET", "POST"]
  }
});

app.use(cors());
app.use(express.json());

// Remote Ollama configuration
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'deepseek-v3.1:671b-cloud';

// Enhanced Medical context for Tunisian patients
const MEDICAL_CONTEXT = `
You are a medical assistant chatbot specifically designed for Tunisian patients. Your role is to:

1. Provide general medical information and symptom analysis
2. Offer health advice and preventive care information
3. Help understand medical conditions and treatments
4. Guide patients to appropriate healthcare resources in Tunisia
IMPORTANT DISCLAIMERS:
- You are not a replacement for professional medical advice
- Always consult with healthcare professionals for serious conditions
- For emergencies, contact Tunisian emergency services (190)
- You provide information only, not diagnoses

Tunisia-specific information:
- Healthcare system: Public and private sectors
- Emergency: 190
- Common languages: Arabic, French, English
- Major hospitals: Charles Nicolle, La Rabta, Mongi Slim
- 
When responding:
- let space between each word
- use arabic tunisien dialect
- Be empathetic and clear
- Use simple language
- focus on patient safety
-helpful and supportive
- keep responses consise
- maintain confidentiality
- never ask for personal data
- never provide prescriptions or specific treatments
- cater to local healthcare context
- Consider Tunisian cultural context
- Suggest local resources when appropriate
- Always emphasize consulting real doctors
- Use arabic tunisien dialect for responses
Now, respond to the patient's query:
`;

class RemoteOllamaService {
  async generateResponse(userMessage, socket) {
    return new Promise(async (resolve, reject) => {
      try {
        console.log('ðŸ“ Medical query from patient:', userMessage);
        
        const medicalPrompt = MEDICAL_CONTEXT + "\n\nØ§Ù„Ù…Ø±ÙŠØ¶: " + userMessage + "\n\nØ§Ù„Ù…Ø³Ø§Ø¹Ø¯:";
        
        console.log('ðŸ”— Connecting to Ollama at:', OLLAMA_BASE_URL);
        
        const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: OLLAMA_MODEL,
            prompt: medicalPrompt,
            stream: true,
            options: {
              temperature: 0.7,
              top_p: 0.9,
              top_k: 40
            }
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`Ollama API error: ${response.status} - ${errorText}`);
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let fullResponse = '';
        let buffer = '';

        const processChunk = (chunk) => {
          buffer += chunk;
          const lines = buffer.split('\n');
          buffer = lines.pop() || ''; // Keep incomplete line in buffer

          for (const line of lines) {
            if (line.trim() === '') continue;
            
            try {
              const data = JSON.parse(line);
              
              if (data.response) {
                fullResponse += data.response;
                
                // Stream to frontend in real-time
                if (socket) {
                  socket.emit('streaming_response', {
                    text: fullResponse,
                    partial: !data.done,
                    complete: data.done
                  });
                }
              }
              
              if (data.done) {
                console.log('âœ… Response completed, total tokens:', data.total_duration);
                resolve(fullResponse);
                return true; // Signal completion
              }
              
            } catch (e) {
              console.warn('âš ï¸ Failed to parse JSON line:', line, 'Error:', e.message);
            }
          }
          return false;
        };

        while (true) {
          const { done, value } = await reader.read();
          
          if (done) {
            // Process any remaining buffer
            if (buffer.trim()) processChunk('');
            break;
          }
          
          const chunk = decoder.decode(value, { stream: true });
          const completed = processChunk(chunk);
          
          if (completed) break;
        }
        
        // If we exit without completion, resolve with what we have
        if (fullResponse) {
          resolve(fullResponse);
        } else {
          throw new Error('No response generated from Ollama');
        }
        
      } catch (error) {
        console.error('âŒ Remote Ollama error:', error);
        
        // Fallback responses in Tunisian Arabic
        const fallbackResponses = [
          "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ù…Ø´ Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø¹Ø¯ Ù‚Ù„ÙŠÙ„ Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø·Ø¨ÙŠØ¨Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø©.",
          "Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø·Ø¨ÙŠ Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø±Ù‚Ù… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ 190 Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø­Ø§Ù„Ø© Ù…Ø³ØªØ¹Ø¬Ù„Ø©.",
          "Ø¹Ø°Ø±Ù‹Ø§ØŒ ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø¤Ù‚ØªØ©. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ¨ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©."
        ];
        
        const fallbackResponse = fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
        
        if (socket) {
          socket.emit('streaming_response', {
            text: fallbackResponse,
            partial: false,
            complete: true
          });
        }
        resolve(fallbackResponse);
      }
    });
  }

  // Health check for remote Ollama
  async healthCheck() {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000);
      
      const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
        method: 'GET',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        const data = await response.json();
        return {
          healthy: true,
          models: data.models || [],
          message: 'Ollama is connected and responding'
        };
      }
      return {
        healthy: false,
        message: `Ollama responded with status: ${response.status}`
      };
    } catch (error) {
      return {
        healthy: false,
        message: `Cannot connect to Ollama: ${error.message}`
      };
    }
  }
}

const medicalService = new RemoteOllamaService();

// Store active connections for monitoring
const activeConnections = new Map();

// Enhanced health check endpoint
app.get('/api/health', async (req, res) => {
  const ollamaHealth = await medicalService.healthCheck();
  
  const healthStatus = {
    status: ollamaHealth.healthy ? 'OK' : 'DEGRADED',
    message: ollamaHealth.healthy ? 'Medical Chatbot Backend is running' : 'Backend running but Ollama unavailable',
    service: 'Tunisian Patient Assistant',
    timestamp: new Date().toISOString(),
    ollama: ollamaHealth,
    connections: {
      active: activeConnections.size,
      total: Array.from(activeConnections.values()).length
    },
    environment: {
      node: process.version,
      platform: process.platform,
      ollama_url: OLLAMA_BASE_URL,
      model: OLLAMA_MODEL
    }
  };
  
  if (ollamaHealth.healthy) {
    res.json(healthStatus);
  } else {
    res.status(503).json(healthStatus);
  }
});

// Test endpoint for quick Ollama check
app.get('/api/test-ollama', async (req, res) => {
  try {
    const testPrompt = "Hello, are you working? Respond in Tunisian Arabic.";
    
    const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: OLLAMA_MODEL,
        prompt: testPrompt,
        stream: false
      })
    });
    
    if (response.ok) {
      const data = await response.json();
      res.json({ 
        success: true, 
        response: data.response,
        model: OLLAMA_MODEL
      });
    } else {
      res.status(500).json({ 
        success: false, 
        error: `Ollama responded with status: ${response.status}` 
      });
    }
  } catch (error) {
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Socket.io for real-time communication
io.on('connection', (socket) => {
  console.log('ðŸ”Œ Medical chatbot user connected:', socket.id);
  activeConnections.set(socket.id, {
    connectedAt: new Date(),
    ip: socket.handshake.address
  });

  // Send welcome message
  socket.emit('connected', {
    message: 'Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø·Ø¨ÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ',
    timestamp: new Date().toISOString()
  });

  socket.on('send_message', async (data) => {
    try {
      console.log('ðŸ’¬ Received medical query from', socket.id, ':', data.message.substring(0, 100) + '...');
      
      // Validate message
      if (!data.message || data.message.trim().length === 0) {
        socket.emit('error', { 
          message: 'Ø¹Ø°Ø±Ù‹Ø§ØŒ ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ø±Ø³Ø§Ù„Ø©.' 
        });
        return;
      }
      
      if (data.message.length > 1000) {
        socket.emit('error', { 
          message: 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§. ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªØµØ§Ø± Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ.' 
        });
        return;
      }
      
      await medicalService.generateResponse(data.message, socket);
      
    } catch (error) {
      console.error('âŒ Error processing medical query:', error);
      socket.emit('error', { 
        message: 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.' 
      });
    }
  });

  socket.on('disconnect', (reason) => {
    console.log('ðŸ”Œ User disconnected:', socket.id, 'Reason:', reason);
    activeConnections.delete(socket.id);
  });

  socket.on('error', (error) => {
    console.error('ðŸ’¥ Socket error for', socket.id, ':', error);
  });
});

// Error handling middleware
app.use((error, req, res, next) => {
  console.error('ðŸ”¥ Server error:', error);
  res.status(500).json({
    error: 'Internal server error',
    message: 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù….'
  });
});

// 404 handler
app.use('*', (req, res) => {
  res.status(404).json({
    error: 'Endpoint not found',
    message: 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.'
  });
});

const PORT = process.env.PORT || 5000;

server.listen(PORT, () => {
  console.log(`
ðŸ¥ Medical Chatbot Server Started!
ðŸ“ Port: ${PORT}
ðŸŽ¯ Service: Tunisian Patient Assistant
ðŸ”— Ollama URL: ${OLLAMA_BASE_URL}
ðŸ¤– Model: ${OLLAMA_MODEL}
ðŸ“Š Health Check: http://localhost:${PORT}/api/health
ðŸ”§ Test Ollama: http://localhost:${PORT}/api/test-ollama
âœ¨ Server is ready and waiting for connections...
  `);
});

// Graceful shutdown
process.on('SIGINT', () => {
  console.log('\nðŸ”» Shutting down gracefully...');
  console.log(`ðŸ”» Closing ${activeConnections.size} active connections`);
  
  server.close(() => {
    console.log('ðŸ”» Server closed');
    process.exit(0);
  });
  
  // Force close after 5 seconds
  setTimeout(() => {
    console.log('ðŸ”» Forcing shutdown');
    process.exit(1);
  }, 5000);
});

module.exports = { app, server, medicalService };
